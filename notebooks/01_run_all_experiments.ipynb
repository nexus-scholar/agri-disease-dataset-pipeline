{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå± Plant Disease Detection: Active Domain Adaptation\n",
    "\n",
    "## Interactive Experiment Runner\n",
    "\n",
    "This notebook provides a **user-friendly interface** to run all experiments without using the command line.\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Experiment Overview\n",
    "\n",
    "| # | Experiment | Purpose | Expected Time |\n",
    "|---|------------|---------|---------------|\n",
    "| 1 | Baseline Gap | Establish the Lab‚ÜíField accuracy drop | ~5 min |\n",
    "| 2 | Passive Augmentation | Test strong data augmentation | ~5 min |\n",
    "| 3 | CutMix | Test CutMix regularization | ~10 min |\n",
    "| 4 | Active Learning | Compare Random vs Entropy | ~15 min |\n",
    "| 5 | Hybrid Warm-Start | **Our proposed method** | ~20 min |\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ How to Use\n",
    "\n",
    "1. **Run cells in order** (Shift+Enter or click ‚ñ∂Ô∏è)\n",
    "2. **Modify parameters** in the configuration cells as needed\n",
    "3. **View results** displayed after each experiment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Configuration\n",
    "\n",
    "Run this cell first to set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP - Run this cell first!\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root\n",
    "notebook_dir = Path(os.getcwd())\n",
    "if 'notebooks' in str(notebook_dir):\n",
    "    project_root = notebook_dir.parent\n",
    "else:\n",
    "    project_root = notebook_dir\n",
    "\n",
    "# Add experiments to path\n",
    "experiments_dir = project_root / 'experiments'\n",
    "sys.path.insert(0, str(experiments_dir))\n",
    "\n",
    "# Verify setup\n",
    "print(\"‚úÖ Setup Complete!\")\n",
    "print(f\"üìÅ Project Root: {project_root}\")\n",
    "print(f\"üìÅ Experiments: {experiments_dir}\")\n",
    "\n",
    "# Check for GPU\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"üíª Running on CPU (slower but works)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Modify these settings as needed\n",
    "# ============================================================\n",
    "\n",
    "# Dataset settings\n",
    "DATASET_ROOT = str(project_root.parent / 'dataset')  # Where pv and PlantDoc are located\n",
    "LAB_FOLDER = 'pv'      # Lab/controlled data\n",
    "FIELD_FOLDER = 'PlantDoc'        # Field/real-world data\n",
    "CLASS_NAME = 'Tomato'            # Filter to specific crop (or None for all)\n",
    "\n",
    "# Training settings\n",
    "BATCH_SIZE = 16                  # Reduce to 8 if you get memory errors\n",
    "EPOCHS = 5                       # Increase for better results (but slower)\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Active learning settings\n",
    "BUDGET_PER_ROUND = 50            # Samples to label each round\n",
    "NUM_ROUNDS = 4                   # Number of active learning rounds\n",
    "\n",
    "print(\"‚úÖ Configuration loaded!\")\n",
    "print(f\"üìä Dataset: {DATASET_ROOT}\")\n",
    "print(f\"üåø Class filter: {CLASS_NAME or 'All classes'}\")\n",
    "print(f\"‚öôÔ∏è Batch size: {BATCH_SIZE}, Epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Experiment 01: Baseline Generalization Gap\n",
    "\n",
    "**Goal**: Train a model on Lab data (PlantVillage) and measure how much accuracy drops on Field data (PlantDoc).\n",
    "\n",
    "**Expected Result**: ~60-70% accuracy drop (this is the problem we're solving!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXPERIMENT 01: Baseline Gap\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üß™ EXPERIMENT 01: Baseline Generalization Gap\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from common import (\n",
    "    TrainingConfig, get_transforms, find_dataset_path,\n",
    "    FilteredImageFolder, create_data_loaders, create_model,\n",
    "    Trainer, evaluate_accuracy, get_device, set_seed,\n",
    "    save_model, MODELS_DIR\n",
    ")\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Setup\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "\n",
    "config = TrainingConfig(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Load data\n",
    "print(\"\\nüìÇ Loading datasets...\")\n",
    "transforms_dict = get_transforms(config)\n",
    "class_filter = [CLASS_NAME] if CLASS_NAME else None\n",
    "\n",
    "# Lab data\n",
    "lab_path, lab_val_path = find_dataset_path(Path(DATASET_ROOT), LAB_FOLDER)\n",
    "if lab_val_path:\n",
    "    train_dataset = FilteredImageFolder(str(lab_path), transforms_dict['train'], class_filter)\n",
    "    val_dataset = FilteredImageFolder(str(lab_val_path), transforms_dict['val'], class_filter)\n",
    "else:\n",
    "    full_dataset = FilteredImageFolder(str(lab_path), transforms_dict['train'], class_filter)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, len(full_dataset) - train_size])\n",
    "\n",
    "class_names = train_dataset.classes if hasattr(train_dataset, 'classes') else train_dataset.dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Field data\n",
    "field_path, _ = find_dataset_path(Path(DATASET_ROOT), FIELD_FOLDER)\n",
    "field_dataset = FilteredImageFolder(str(field_path), transforms_dict['val'], class_filter)\n",
    "\n",
    "print(f\"‚úÖ Lab train: {len(train_dataset)} images\")\n",
    "print(f\"‚úÖ Lab val: {len(val_dataset)} images\")\n",
    "print(f\"‚úÖ Field test: {len(field_dataset)} images\")\n",
    "print(f\"üìã Classes: {class_names}\")\n",
    "\n",
    "# Create loaders\n",
    "loaders = create_data_loaders(train_dataset, val_dataset, field_dataset, config)\n",
    "\n",
    "# Create and train model\n",
    "print(\"\\nüîß Creating model...\")\n",
    "model = create_model(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"\\nüèãÔ∏è Training...\")\n",
    "trainer = Trainer(model, device, config)\n",
    "model = trainer.train(loaders['train'], loaders['val'], epochs=config.epochs)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüìä Evaluating...\")\n",
    "lab_acc = evaluate_accuracy(model, loaders['val'], device, desc=\"Lab\")\n",
    "field_acc = evaluate_accuracy(model, loaders['test'], device, desc=\"Field\")\n",
    "gap = lab_acc - field_acc\n",
    "\n",
    "# Save model\n",
    "save_model(model, MODELS_DIR / 'baseline_model.pth')\n",
    "\n",
    "# Results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESULTS: Baseline Gap\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üè† Lab Accuracy:   {lab_acc:.2f}%\")\n",
    "print(f\"üåæ Field Accuracy: {field_acc:.2f}%\")\n",
    "print(f\"üìâ GAP: {gap:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Store for comparison\n",
    "exp01_results = {'lab': lab_acc, 'field': field_acc, 'gap': gap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Experiment 02: Passive Augmentation\n",
    "\n",
    "**Goal**: Test if strong data augmentation during training can improve field robustness.\n",
    "\n",
    "**Augmentations used**:\n",
    "- üîÑ Flips, rotations\n",
    "- ‚òÄÔ∏è Brightness, contrast changes\n",
    "- üå´Ô∏è Blur, noise\n",
    "- ‚¨õ Random dropout (occlusion simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXPERIMENT 02: Passive Augmentation\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üß™ EXPERIMENT 02: Passive Augmentation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "# Strong augmentation pipeline\n",
    "aug_train = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "aug_val = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Custom dataset with Albumentations\n",
    "class AugDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, aug, class_filter=None):\n",
    "        super().__init__(root, transform=None)\n",
    "        self.aug = aug\n",
    "        if class_filter:\n",
    "            orig = self.classes.copy()\n",
    "            matched = [c for c in orig if any(f.lower() in c.lower() for f in class_filter)]\n",
    "            if matched:\n",
    "                self.classes = matched\n",
    "                self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "                self.samples = [(p, self.class_to_idx[orig[i]]) for p, i in self.samples if orig[i] in self.classes]\n",
    "                self.targets = [s[1] for s in self.samples]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) if img is not None else np.zeros((224,224,3), dtype=np.uint8)\n",
    "        img = self.aug(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# Load data with augmentation\n",
    "print(\"\\nüìÇ Loading data with strong augmentation...\")\n",
    "filter_cls = [CLASS_NAME] if CLASS_NAME else None\n",
    "\n",
    "train_ds = AugDataset(str(lab_path), aug_train, filter_cls)\n",
    "val_ds = AugDataset(str(lab_val_path) if lab_val_path else str(lab_path), aug_val, filter_cls)\n",
    "field_ds = AugDataset(str(field_path), aug_val, filter_cls)\n",
    "\n",
    "if not lab_val_path:\n",
    "    train_size = int(0.8 * len(train_ds))\n",
    "    train_ds, val_ds = random_split(train_ds, [train_size, len(train_ds) - train_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "field_loader = DataLoader(field_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"‚úÖ Train: {len(train_ds)} | Val: {len(val_ds)} | Field: {len(field_ds)}\")\n",
    "\n",
    "# Train\n",
    "print(\"\\nüèãÔ∏è Training with augmentation...\")\n",
    "model2 = create_model(num_classes).to(device)\n",
    "optimizer = optim.Adam(model2.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_acc = 0\n",
    "best_weights = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model2.train()\n",
    "    correct = total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    train_acc = correct / total\n",
    "    val_acc = evaluate_accuracy(model2, val_loader, device) / 100\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train: {train_acc:.4f} | Val: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_weights = copy.deepcopy(model2.state_dict())\n",
    "\n",
    "model2.load_state_dict(best_weights)\n",
    "\n",
    "# Evaluate\n",
    "lab_acc2 = evaluate_accuracy(model2, val_loader, device)\n",
    "field_acc2 = evaluate_accuracy(model2, field_loader, device)\n",
    "gap2 = lab_acc2 - field_acc2\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESULTS: Passive Augmentation\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üè† Lab Accuracy:   {lab_acc2:.2f}%\")\n",
    "print(f\"üåæ Field Accuracy: {field_acc2:.2f}%\")\n",
    "print(f\"üìâ GAP: {gap2:.2f}%\")\n",
    "print(f\"\\nüìà Improvement over baseline: {field_acc2 - exp01_results['field']:+.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "exp02_results = {'lab': lab_acc2, 'field': field_acc2, 'gap': gap2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Experiment 03: CutMix Augmentation\n",
    "\n",
    "**Goal**: Test CutMix - cutting patches from one image and pasting onto another.\n",
    "\n",
    "**Why it helps**: Forces the model to learn from multiple regions, improving robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXPERIMENT 03: CutMix\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üß™ EXPERIMENT 03: CutMix Augmentation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "CUTMIX_PROB = 0.5  # Probability of applying CutMix\n",
    "CUTMIX_BETA = 1.0  # Beta distribution parameter\n",
    "CUTMIX_EPOCHS = 10  # CutMix needs more epochs\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"Generate random bounding box for CutMix.\"\"\"\n",
    "    W, H = size[2], size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w, cut_h = int(W * cut_rat), int(H * cut_rat)\n",
    "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# Use standard transforms for CutMix\n",
    "train_ds3 = FilteredImageFolder(str(lab_path), transforms_dict['train'], class_filter)\n",
    "if not lab_val_path:\n",
    "    train_size = int(0.8 * len(train_ds3))\n",
    "    train_ds3, _ = random_split(train_ds3, [train_size, len(train_ds3) - train_size])\n",
    "\n",
    "train_loader3 = DataLoader(train_ds3, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "# Train with CutMix\n",
    "print(\"\\nüèãÔ∏è Training with CutMix...\")\n",
    "model3 = create_model(num_classes).to(device)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
    "criterion3 = nn.CrossEntropyLoss()\n",
    "\n",
    "best_acc3 = 0\n",
    "best_weights3 = None\n",
    "\n",
    "for epoch in range(CUTMIX_EPOCHS):\n",
    "    model3.train()\n",
    "    correct = total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader3:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer3.zero_grad()\n",
    "        \n",
    "        # Apply CutMix with probability\n",
    "        if np.random.rand() < CUTMIX_PROB:\n",
    "            lam = np.random.beta(CUTMIX_BETA, CUTMIX_BETA)\n",
    "            rand_index = torch.randperm(inputs.size(0)).to(device)\n",
    "            labels_a, labels_b = labels, labels[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "            outputs = model3(inputs)\n",
    "            loss = criterion3(outputs, labels_a) * lam + criterion3(outputs, labels_b) * (1. - lam)\n",
    "        else:\n",
    "            outputs = model3(inputs)\n",
    "            loss = criterion3(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer3.step()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    train_acc = correct / total\n",
    "    val_acc = evaluate_accuracy(model3, loaders['val'], device) / 100\n",
    "    print(f\"Epoch {epoch+1}/{CUTMIX_EPOCHS} | Train: {train_acc:.4f} (mixed) | Val: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_acc3:\n",
    "        best_acc3 = val_acc\n",
    "        best_weights3 = copy.deepcopy(model3.state_dict())\n",
    "\n",
    "model3.load_state_dict(best_weights3)\n",
    "\n",
    "# Evaluate\n",
    "lab_acc3 = evaluate_accuracy(model3, loaders['val'], device)\n",
    "field_acc3 = evaluate_accuracy(model3, loaders['test'], device)\n",
    "gap3 = lab_acc3 - field_acc3\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESULTS: CutMix\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üè† Lab Accuracy:   {lab_acc3:.2f}%\")\n",
    "print(f\"üåæ Field Accuracy: {field_acc3:.2f}%\")\n",
    "print(f\"üìâ GAP: {gap3:.2f}%\")\n",
    "print(f\"\\nüìà Improvement over baseline: {field_acc3 - exp01_results['field']:+.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "exp03_results = {'lab': lab_acc3, 'field': field_acc3, 'gap': gap3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Experiment 04: Active Learning Comparison\n",
    "\n",
    "**Goal**: Compare Random vs Entropy-based sample selection for active learning.\n",
    "\n",
    "**Setup**:\n",
    "- Start with baseline model\n",
    "- Iteratively select field samples to \"label\"\n",
    "- Fine-tune and evaluate\n",
    "\n",
    "**Key Observation**: Entropy shows an early \"dip\" because it picks hard samples first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXPERIMENT 04: Active Learning\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üß™ EXPERIMENT 04: Active Learning Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "from common import load_model, MODELS_DIR\n",
    "\n",
    "FINE_TUNE_LR = 0.0001\n",
    "EPOCHS_PER_ROUND = 5\n",
    "\n",
    "def compute_entropy(model, loader, device):\n",
    "    \"\"\"Compute uncertainty scores.\"\"\"\n",
    "    model.eval()\n",
    "    entropies = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            entropy = -(probs * torch.log(probs + 1e-10)).sum(dim=1)\n",
    "            entropies.extend(entropy.cpu().numpy())\n",
    "    return np.array(entropies)\n",
    "\n",
    "def fine_tune(model, loader, epochs, device):\n",
    "    \"\"\"Fine-tune on labeled samples.\"\"\"\n",
    "    model.train()\n",
    "    opt = optim.Adam(model.parameters(), lr=FINE_TUNE_LR)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs):\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(inputs), labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return model\n",
    "\n",
    "def run_al_simulation(strategy, pool_ds, test_ds):\n",
    "    \"\"\"Run active learning simulation.\"\"\"\n",
    "    print(f\"\\n‚ñ∂ Strategy: {strategy.upper()}\")\n",
    "    \n",
    "    # Load fresh baseline\n",
    "    model = load_model(MODELS_DIR / 'baseline_model.pth', num_classes, device)\n",
    "    \n",
    "    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "    pool_indices = list(range(len(pool_ds)))\n",
    "    labeled_indices = []\n",
    "    results = []\n",
    "    \n",
    "    # Initial\n",
    "    acc = evaluate_accuracy(model, test_loader, device)\n",
    "    print(f\"  0 labels: {acc:.2f}%\")\n",
    "    results.append(acc)\n",
    "    \n",
    "    cumulative = 0\n",
    "    for round_num in range(NUM_ROUNDS):\n",
    "        cumulative += BUDGET_PER_ROUND\n",
    "        \n",
    "        # Select samples\n",
    "        if strategy == 'random':\n",
    "            np.random.shuffle(pool_indices)\n",
    "            selected = pool_indices[:BUDGET_PER_ROUND]\n",
    "            pool_indices = pool_indices[BUDGET_PER_ROUND:]\n",
    "        else:  # entropy\n",
    "            pool_subset = Subset(pool_ds, pool_indices)\n",
    "            pool_loader = DataLoader(pool_subset, batch_size=32, shuffle=False)\n",
    "            uncertainties = compute_entropy(model, pool_loader, device)\n",
    "            sorted_idx = np.argsort(uncertainties)[::-1]\n",
    "            sorted_pool = [pool_indices[i] for i in sorted_idx]\n",
    "            selected = sorted_pool[:BUDGET_PER_ROUND]\n",
    "            pool_indices = sorted_pool[BUDGET_PER_ROUND:]\n",
    "        \n",
    "        labeled_indices.extend(selected)\n",
    "        \n",
    "        # Fine-tune\n",
    "        train_subset = Subset(pool_ds, labeled_indices)\n",
    "        train_loader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
    "        model = fine_tune(model, train_loader, EPOCHS_PER_ROUND, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        acc = evaluate_accuracy(model, test_loader, device)\n",
    "        print(f\"  {cumulative} labels: {acc:.2f}%\")\n",
    "        results.append(acc)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Prepare field data\n",
    "print(\"\\nüìÇ Preparing field data...\")\n",
    "pool_ds = FilteredImageFolder(str(field_path), transforms_dict['train'], class_filter)\n",
    "test_ds_al = FilteredImageFolder(str(field_path), transforms_dict['val'], class_filter)\n",
    "\n",
    "# Split 80/20\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(pool_ds))\n",
    "split = int(0.8 * len(pool_ds))\n",
    "pool_subset = Subset(pool_ds, indices[:split].tolist())\n",
    "test_subset = Subset(test_ds_al, indices[split:].tolist())\n",
    "\n",
    "print(f\"‚úÖ Pool: {len(pool_subset)} | Test: {len(test_subset)}\")\n",
    "\n",
    "# Run simulations\n",
    "results_random = run_al_simulation('random', pool_subset, test_subset)\n",
    "results_entropy = run_al_simulation('entropy', pool_subset, test_subset)\n",
    "\n",
    "# Results table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESULTS: Active Learning Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Labels':<10} | {'Random':<12} | {'Entropy':<12} | {'Diff'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "x_values = [0] + [BUDGET_PER_ROUND * (i+1) for i in range(NUM_ROUNDS)]\n",
    "for i, x in enumerate(x_values):\n",
    "    diff = results_entropy[i] - results_random[i]\n",
    "    print(f\"{x:<10} | {results_random[i]:>10.2f}% | {results_entropy[i]:>10.2f}% | {diff:+.2f}%\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "exp04_results = {'random': results_random, 'entropy': results_entropy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Experiment 05: Hybrid Warm-Start (Our Proposed Method)\n",
    "\n",
    "**Goal**: Combine Random + Entropy sampling to get the best of both.\n",
    "\n",
    "**The Hybrid Strategy**:\n",
    "- **Round 0**: 50% Random + 50% Entropy (warm start)\n",
    "- **Later rounds**: Pure entropy sampling\n",
    "\n",
    "**Why it works**: Avoids the early \"dip\" while still benefiting from uncertainty sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXPERIMENT 05: Hybrid Warm-Start (PROPOSED METHOD)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üß™ EXPERIMENT 05: Hybrid Warm-Start (OUR METHOD)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def run_hybrid_simulation(pool_ds, test_ds):\n",
    "    \"\"\"Run hybrid active learning simulation.\"\"\"\n",
    "    print(f\"\\n‚ñ∂ Strategy: HYBRID\")\n",
    "    \n",
    "    model = load_model(MODELS_DIR / 'baseline_model.pth', num_classes, device)\n",
    "    \n",
    "    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "    pool_indices = list(range(len(pool_ds)))\n",
    "    labeled_indices = []\n",
    "    results = []\n",
    "    \n",
    "    # Initial\n",
    "    acc = evaluate_accuracy(model, test_loader, device)\n",
    "    print(f\"  0 labels: {acc:.2f}%\")\n",
    "    results.append(acc)\n",
    "    \n",
    "    cumulative = 0\n",
    "    for round_num in range(NUM_ROUNDS):\n",
    "        cumulative += BUDGET_PER_ROUND\n",
    "        \n",
    "        if round_num == 0:\n",
    "            # WARM START: 50% random + 50% entropy\n",
    "            n_random = BUDGET_PER_ROUND // 2\n",
    "            n_entropy = BUDGET_PER_ROUND - n_random\n",
    "            print(f\"  üî• Warm start: {n_random} random + {n_entropy} entropy\")\n",
    "            \n",
    "            # Random part\n",
    "            np.random.shuffle(pool_indices)\n",
    "            random_sel = pool_indices[:n_random]\n",
    "            remaining = pool_indices[n_random:]\n",
    "            \n",
    "            # Entropy part\n",
    "            pool_subset = Subset(pool_ds, remaining)\n",
    "            pool_loader = DataLoader(pool_subset, batch_size=32, shuffle=False)\n",
    "            uncertainties = compute_entropy(model, pool_loader, device)\n",
    "            sorted_idx = np.argsort(uncertainties)[::-1]\n",
    "            sorted_remaining = [remaining[i] for i in sorted_idx]\n",
    "            entropy_sel = sorted_remaining[:n_entropy]\n",
    "            pool_indices = sorted_remaining[n_entropy:]\n",
    "            \n",
    "            selected = random_sel + entropy_sel\n",
    "        else:\n",
    "            # Pure entropy for later rounds\n",
    "            pool_subset = Subset(pool_ds, pool_indices)\n",
    "            pool_loader = DataLoader(pool_subset, batch_size=32, shuffle=False)\n",
    "            uncertainties = compute_entropy(model, pool_loader, device)\n",
    "            sorted_idx = np.argsort(uncertainties)[::-1]\n",
    "            sorted_pool = [pool_indices[i] for i in sorted_idx]\n",
    "            selected = sorted_pool[:BUDGET_PER_ROUND]\n",
    "            pool_indices = sorted_pool[BUDGET_PER_ROUND:]\n",
    "        \n",
    "        labeled_indices.extend(selected)\n",
    "        \n",
    "        # Fine-tune\n",
    "        train_subset = Subset(pool_ds, labeled_indices)\n",
    "        train_loader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
    "        model = fine_tune(model, train_loader, EPOCHS_PER_ROUND, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        acc = evaluate_accuracy(model, test_loader, device)\n",
    "        print(f\"  {cumulative} labels: {acc:.2f}%\")\n",
    "        results.append(acc)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run hybrid\n",
    "results_hybrid = run_hybrid_simulation(pool_subset, test_subset)\n",
    "\n",
    "# Final comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL RESULTS: All Strategies\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Labels':<10} | {'Random':<12} | {'Entropy':<12} | {'Hybrid':<12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for i, x in enumerate(x_values):\n",
    "    r, e, h = results_random[i], results_entropy[i], results_hybrid[i]\n",
    "    best = max(r, e, h)\n",
    "    row = f\"{x:<10} | {r:>10.2f}% | {e:>10.2f}% | {h:>10.2f}%\"\n",
    "    if h == best:\n",
    "        row += \" ‚≠ê\"\n",
    "    print(row)\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Winner\n",
    "final_random = results_random[-1]\n",
    "final_entropy = results_entropy[-1]\n",
    "final_hybrid = results_hybrid[-1]\n",
    "\n",
    "print(f\"\\nüèÜ FINAL ACCURACY WITH {BUDGET_PER_ROUND * NUM_ROUNDS} LABELS:\")\n",
    "print(f\"   Random:  {final_random:.2f}%\")\n",
    "print(f\"   Entropy: {final_entropy:.2f}%\")\n",
    "print(f\"   Hybrid:  {final_hybrid:.2f}% {'‚≠ê BEST' if final_hybrid >= max(final_random, final_entropy) else ''}\")\n",
    "\n",
    "exp05_results = {'random': results_random, 'entropy': results_entropy, 'hybrid': results_hybrid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Summary: All Experiments Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SUMMARY OF ALL EXPERIMENTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä COMPLETE EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüî¨ PASSIVE METHODS (No field data used):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Method':<25} | {'Lab Acc':<10} | {'Field Acc':<10} | {'Gap'}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Baseline':<25} | {exp01_results['lab']:>8.2f}% | {exp01_results['field']:>8.2f}% | {exp01_results['gap']:.2f}%\")\n",
    "print(f\"{'+ Passive Augmentation':<25} | {exp02_results['lab']:>8.2f}% | {exp02_results['field']:>8.2f}% | {exp02_results['gap']:.2f}%\")\n",
    "print(f\"{'+ CutMix':<25} | {exp03_results['lab']:>8.2f}% | {exp03_results['field']:>8.2f}% | {exp03_results['gap']:.2f}%\")\n",
    "\n",
    "print(\"\\nüéØ ACTIVE METHODS (Using field data budget):\")\n",
    "print(\"-\" * 50)\n",
    "total_budget = BUDGET_PER_ROUND * NUM_ROUNDS\n",
    "print(f\"With {total_budget} labeled field images:\")\n",
    "print(f\"  Random sampling:  {exp05_results['random'][-1]:.2f}%\")\n",
    "print(f\"  Entropy sampling: {exp05_results['entropy'][-1]:.2f}%\")\n",
    "print(f\"  Hybrid (Ours):    {exp05_results['hybrid'][-1]:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÜ KEY FINDINGS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"1. Baseline gap: {exp01_results['gap']:.1f}% accuracy drop from Lab to Field\")\n",
    "print(f\"2. Passive augmentation helps but doesn't solve the problem\")\n",
    "print(f\"3. Active learning with {total_budget} labels significantly improves field accuracy\")\n",
    "print(f\"4. Hybrid warm-start achieves the best results\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PLOT RESULTS\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Passive methods comparison\n",
    "ax1 = axes[0]\n",
    "methods = ['Baseline', 'Passive Aug', 'CutMix']\n",
    "lab_accs = [exp01_results['lab'], exp02_results['lab'], exp03_results['lab']]\n",
    "field_accs = [exp01_results['field'], exp02_results['field'], exp03_results['field']]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, lab_accs, width, label='Lab', color='#2ecc71')\n",
    "bars2 = ax1.bar(x + width/2, field_accs, width, label='Field', color='#e74c3c')\n",
    "\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_title('Passive Methods Comparison')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(methods)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                 xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Plot 2: Active learning curves\n",
    "ax2 = axes[1]\n",
    "ax2.plot(x_values, exp05_results['random'], 'o-', label='Random', color='gray', linewidth=2)\n",
    "ax2.plot(x_values, exp05_results['entropy'], 's-', label='Entropy', color='#f39c12', linewidth=2)\n",
    "ax2.plot(x_values, exp05_results['hybrid'], '^-', label='Hybrid (Ours)', color='#e74c3c', linewidth=2, markersize=8)\n",
    "\n",
    "ax2.set_xlabel('Number of Labeled Field Images')\n",
    "ax2.set_ylabel('Field Test Accuracy (%)')\n",
    "ax2.set_title('Active Learning Strategies Comparison')\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(project_root / 'results' / 'figures' / 'notebook_results.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Figure saved to results/figures/notebook_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Done!\n",
    "\n",
    "You have successfully run all experiments. The key takeaways are:\n",
    "\n",
    "1. **The Problem**: Models trained on lab data lose ~60-70% accuracy on field data\n",
    "2. **Passive solutions** (augmentation, CutMix) help slightly but don't solve the problem\n",
    "3. **Active learning** with a small labeling budget significantly improves results\n",
    "4. **Our Hybrid method** achieves the best performance by avoiding the entropy \"dip\"\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps**:\n",
    "- Try different class filters (e.g., `CLASS_NAME = 'Apple'`)\n",
    "- Adjust the labeling budget to see its effect\n",
    "- Run with more epochs for better results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
